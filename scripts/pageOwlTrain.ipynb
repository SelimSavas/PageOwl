{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv8 Tutorial",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac254c1-862a-4836-cd70-0208c294b97d"
      },
      "source": [
        "%pip install ultralytics\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 26.3/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"Pho4XVVaJnNcR3y3HNrK\")\n",
        "project = rf.workspace(\"gazi-university-6bdmi\").project(\"pageowl\")\n",
        "dataset = project.version(1).download(\"yolov8\")"
      ],
      "metadata": {
        "id": "DO3nOeWnKybW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O",
        "outputId": "de785c29-8d5b-4196-b455-684a9f6fcf90",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train YOLOv8n on COCO8 for 3 epochs\n",
        "!yolo train model=yolov8n.pt data=/content/PageOwl-1/data.yaml epochs=16 imgsz=640"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/PageOwl-1/data.yaml, epochs=16, time=None, patience=50, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train4, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train4\n",
            "2023-12-22 01:43:41.749744: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-12-22 01:43:41.749798: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-12-22 01:43:41.751077: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=80 with nc=2\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    751702  ultralytics.nn.modules.head.Detect           [2, [64, 128, 256]]           \n",
            "Model summary: 225 layers, 3011238 parameters, 3011222 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train4', view at http://localhost:6006/\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/PageOwl-1/train/labels.cache... 147 images, 0 backgrounds, 0 corrupt: 100% 147/147 [00:00<?, ?it/s]\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/PageOwl-1/valid/labels.cache... 6 images, 0 backgrounds, 0 corrupt: 100% 6/6 [00:00<?, ?it/s]\n",
            "Plotting labels to runs/detect/train4/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "16 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       1/16      2.43G      1.672      3.426      1.538          8        640: 100% 10/10 [00:08<00:00,  1.13it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:01<00:00,  1.46s/it]\n",
            "                   all          6         13     0.0071      0.944     0.0683     0.0431\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       2/16       2.3G      1.275      2.691      1.278          8        640: 100% 10/10 [00:03<00:00,  2.56it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.69it/s]\n",
            "                   all          6         13    0.00675      0.944      0.441       0.33\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       3/16       2.3G      1.047      1.856      1.133         14        640: 100% 10/10 [00:02<00:00,  3.95it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.58it/s]\n",
            "                   all          6         13        0.9      0.222      0.491      0.309\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       4/16       2.3G      1.021      1.608      1.086          9        640: 100% 10/10 [00:04<00:00,  2.33it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.07it/s]\n",
            "                   all          6         13      0.786      0.514      0.657      0.485\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       5/16       2.3G      0.911      1.474      1.029          4        640: 100% 10/10 [00:02<00:00,  3.59it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.09it/s]\n",
            "                   all          6         13      0.804      0.472        0.7      0.511\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       6/16      2.32G     0.8871      1.264     0.9938         14        640: 100% 10/10 [00:02<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  4.78it/s]\n",
            "                   all          6         13      0.791      0.594      0.855      0.544\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       7/16      2.27G      0.874       1.49      1.006          6        640: 100% 10/10 [00:10<00:00,  1.03s/it]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  8.24it/s]\n",
            "                   all          6         13      0.379      0.358      0.471      0.336\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       8/16      2.29G     0.8919      1.453      1.009          6        640: 100% 10/10 [00:03<00:00,  2.76it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.20it/s]\n",
            "                   all          6         13      0.927      0.562      0.831      0.591\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "       9/16      2.27G     0.8133       1.32     0.9777          7        640: 100% 10/10 [00:03<00:00,  2.75it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.19it/s]\n",
            "                   all          6         13      0.593      0.718      0.598      0.381\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      10/16      2.28G     0.8261      1.307     0.9925          4        640: 100% 10/10 [00:02<00:00,  3.89it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.36it/s]\n",
            "                   all          6         13      0.572      0.778      0.678      0.421\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      11/16      2.29G      0.761      1.141     0.9643          6        640: 100% 10/10 [00:02<00:00,  3.94it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.16it/s]\n",
            "                   all          6         13      0.939      0.889      0.897      0.647\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      12/16      2.29G     0.7644      1.125     0.9821          8        640: 100% 10/10 [00:02<00:00,  3.52it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  3.60it/s]\n",
            "                   all          6         13      0.763       0.82      0.888      0.634\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      13/16      2.29G     0.6946      1.158     0.9392          6        640: 100% 10/10 [00:02<00:00,  3.46it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.41it/s]\n",
            "                   all          6         13      0.919      0.887      0.921      0.663\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      14/16      2.29G     0.6704      1.084     0.9425          9        640: 100% 10/10 [00:02<00:00,  3.78it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.49it/s]\n",
            "                   all          6         13      0.953      0.889      0.934       0.67\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      15/16      2.29G     0.6835     0.9505     0.9069         10        640: 100% 10/10 [00:02<00:00,  3.81it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  5.84it/s]\n",
            "                   all          6         13      0.926      0.891      0.972      0.708\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "      16/16      2.29G     0.6717     0.9923     0.9086         16        640: 100% 10/10 [00:04<00:00,  2.40it/s]\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.66it/s]\n",
            "                   all          6         13      0.952      0.988      0.995      0.719\n",
            "\n",
            "16 epochs completed in 0.025 hours.\n",
            "Optimizer stripped from runs/detect/train4/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from runs/detect/train4/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating runs/detect/train4/weights/best.pt...\n",
            "Ultralytics YOLOv8.0.228 ðŸš€ Python-3.10.12 torch-2.1.0+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Model summary (fused): 168 layers, 3006038 parameters, 0 gradients, 8.1 GFLOPs\n",
            "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 1/1 [00:00<00:00,  6.83it/s]\n",
            "                   all          6         13      0.952      0.988      0.995      0.722\n",
            "                     0          6          9          1      0.976      0.995      0.767\n",
            "                     1          6          4      0.904          1      0.995      0.676\n",
            "Speed: 0.2ms preprocess, 4.8ms inference, 0.0ms loss, 4.5ms postprocess per image\n",
            "Results saved to \u001b[1mruns/detect/train4\u001b[0m\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/train\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Load a model\n",
        "model = YOLO('/content/runs/detect/train4/weights/best.pt')  # pretrained YOLOv8n model\n",
        "\n",
        "# Run batched inference on a list of images\n",
        "results = model(['/content/PageOwl-1/test/images/example-pdf_page6_jpg.rf.4a5720930234b4be6ac404b49052ac9f.jpg'])  # return a list of Results objects\n",
        "\n",
        "# Process results list\n",
        "for result in results:\n",
        "    boxes = result.boxes  # Boxes object for bbox outputs\n",
        "    masks = result.masks  # Masks object for segmentation masks outputs\n",
        "    keypoints = result.keypoints  # Keypoints object for pose outputs\n",
        "    probs = result.probs  # Probs object for classification outputs\n",
        "    print(boxes)"
      ],
      "metadata": {
        "id": "GnTdJUHCNiw0",
        "outputId": "6d04eb4f-b903-47a3-f94e-f5214487f4ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "0: 640x512 7 1s, 10.9ms\n",
            "Speed: 4.8ms preprocess, 10.9ms inference, 2.6ms postprocess per image at shape (1, 3, 640, 512)\n",
            "ultralytics.engine.results.Boxes object with attributes:\n",
            "\n",
            "cls: tensor([1., 1., 1., 1., 1., 1., 1.], device='cuda:0')\n",
            "conf: tensor([0.9869, 0.9863, 0.9792, 0.9761, 0.3926, 0.3464, 0.3203], device='cuda:0')\n",
            "data: tensor([[1.2744e+02, 9.7458e+02, 1.4467e+03, 1.1782e+03, 9.8689e-01, 1.0000e+00],\n",
            "        [1.2901e+02, 1.1199e+02, 1.4539e+03, 3.3974e+02, 9.8635e-01, 1.0000e+00],\n",
            "        [1.2867e+02, 4.1900e+02, 1.4526e+03, 6.1710e+02, 9.7925e-01, 1.0000e+00],\n",
            "        [1.3048e+02, 7.0646e+02, 1.4532e+03, 8.8377e+02, 9.7611e-01, 1.0000e+00],\n",
            "        [1.3129e+02, 7.1850e+02, 1.0137e+03, 8.9237e+02, 3.9262e-01, 1.0000e+00],\n",
            "        [1.3720e+02, 9.9172e+02, 1.0589e+03, 1.1782e+03, 3.4644e-01, 1.0000e+00],\n",
            "        [1.3113e+02, 4.3136e+02, 9.6694e+02, 6.0500e+02, 3.2032e-01, 1.0000e+00]], device='cuda:0')\n",
            "id: None\n",
            "is_track: False\n",
            "orig_shape: (2048, 1582)\n",
            "shape: torch.Size([7, 6])\n",
            "xywh: tensor([[ 787.0630, 1076.3737, 1319.2412,  203.5930],\n",
            "        [ 791.4510,  225.8629, 1324.8868,  227.7462],\n",
            "        [ 790.6175,  518.0519, 1323.8861,  198.1032],\n",
            "        [ 791.8324,  795.1133, 1322.7070,  177.3096],\n",
            "        [ 572.5101,  805.4386,  882.4349,  173.8683],\n",
            "        [ 598.0704, 1084.9670,  921.7378,  186.5006],\n",
            "        [ 549.0361,  518.1764,  835.8113,  173.6407]], device='cuda:0')\n",
            "xywhn: tensor([[0.4975, 0.5256, 0.8339, 0.0994],\n",
            "        [0.5003, 0.1103, 0.8375, 0.1112],\n",
            "        [0.4998, 0.2530, 0.8368, 0.0967],\n",
            "        [0.5005, 0.3882, 0.8361, 0.0866],\n",
            "        [0.3619, 0.3933, 0.5578, 0.0849],\n",
            "        [0.3780, 0.5298, 0.5826, 0.0911],\n",
            "        [0.3471, 0.2530, 0.5283, 0.0848]], device='cuda:0')\n",
            "xyxy: tensor([[ 127.4424,  974.5771, 1446.6836, 1178.1702],\n",
            "        [ 129.0076,  111.9898, 1453.8944,  339.7360],\n",
            "        [ 128.6744,  419.0003, 1452.5605,  617.1036],\n",
            "        [ 130.4789,  706.4585, 1453.1859,  883.7681],\n",
            "        [ 131.2926,  718.5044, 1013.7275,  892.3727],\n",
            "        [ 137.2016,  991.7168, 1058.9393, 1178.2174],\n",
            "        [ 131.1305,  431.3560,  966.9418,  604.9968]], device='cuda:0')\n",
            "xyxyn: tensor([[0.0806, 0.4759, 0.9145, 0.5753],\n",
            "        [0.0815, 0.0547, 0.9190, 0.1659],\n",
            "        [0.0813, 0.2046, 0.9182, 0.3013],\n",
            "        [0.0825, 0.3450, 0.9186, 0.4315],\n",
            "        [0.0830, 0.3508, 0.6408, 0.4357],\n",
            "        [0.0867, 0.4842, 0.6694, 0.5753],\n",
            "        [0.0829, 0.2106, 0.6112, 0.2954]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "# Ã–rnek bounding box'larÄ± (gerÃ§ek bounding box'larÄ±nÄ±zla deÄŸiÅŸtirin)\n",
        "bounding_boxes = boxes.xyxy\n",
        "\n",
        "# GÃ¶rÃ¼ntÃ¼yÃ¼ yÃ¼kleme\n",
        "image_path = '/content/PageOwl-1/test/images/example-pdf_page6_jpg.rf.4a5720930234b4be6ac404b49052ac9f.jpg'\n",
        "image = Image.open(image_path)\n",
        "\n",
        "# Her bounding box'u kÄ±rpma ve kaydetme\n",
        "for i, box in enumerate(bounding_boxes):\n",
        "    x1, y1, x2, y2 = box.tolist()\n",
        "    cropped_image = image.crop((x1, y1, x2, y2))\n",
        "\n",
        "    # KÄ±rpÄ±lmÄ±ÅŸ resmi kaydetme\n",
        "    output_folder = f'/content/cropped_images/{i}/'  # Her kÄ±rpÄ±lmÄ±ÅŸ resmin kaydedileceÄŸi klasÃ¶r\n",
        "    os.makedirs(output_folder, exist_ok=True)  # KlasÃ¶rÃ¼ oluÅŸtur, varsa yeniden oluÅŸturma\n",
        "    cropped_image.save(os.path.join(output_folder, f'cropped_image_{i}.jpg'))\n",
        "\n",
        "print(\"KÄ±rpÄ±lmÄ±ÅŸ resimler baÅŸarÄ±yla kaydedildi.\")\n"
      ],
      "metadata": {
        "id": "rn9W6BvNOwC3",
        "outputId": "50656565-aa1e-4348-a265-e733a2cd1fd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KÄ±rpÄ±lmÄ±ÅŸ resimler baÅŸarÄ±yla kaydedildi.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wl1S_48XP1Hz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}